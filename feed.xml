<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://androsaba.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://androsaba.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-29T12:58:41+00:00</updated><id>https://androsaba.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Decision Making Needs Modeling Intervention Effects</title><link href="https://androsaba.github.io/blog/2023/treatment_effect_modeling/" rel="alternate" type="text/html" title="Decision Making Needs Modeling Intervention Effects"/><published>2023-11-29T00:00:00+00:00</published><updated>2023-11-29T00:00:00+00:00</updated><id>https://androsaba.github.io/blog/2023/treatment_effect_modeling</id><content type="html" xml:base="https://androsaba.github.io/blog/2023/treatment_effect_modeling/"><![CDATA[<h2 id="problem-with-ml">Problem with ML</h2> <p>Predictive machine learning models are built to improve decision making process. Usually they are embedded in complex decision logic. There are many processes that are intervened by us based on the predictions our ML model makes. For instance, consider churn prevention problem.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/churn.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We build a churn prediction model, then we score the entire customer base, customers with the highest churn scores are identified and customer experience team sends them relevant offers retain them. After receiving offers some of them do not churn but some leave anyway. Few months later the churn model needs to be retrained on the new sample where persuadable customers (the ones that were contacted and stayed) are labeled as 0, while the lost ones (the ones that were contacted but left) are labeled as 1. Therefore former gets low score whereas the latter gets high score. So the new model learns to stop calling persuadable customers and keep calling lost customers. None of them is a decision we want to make. What this use case teaches us is that</p> <div style="background-color: rgba(0, 0, 0, 0.0470588); text-align: center; vertical-align: middle; padding: 20px 0; margin: 0px 0 20px;"> <strong>ignoring interventions leads to wrong decisions.</strong> </div> <p>One should estimate the intervention effect or, in this case, probability of churn given intervention instead of simply retraining the model.</p> <p>In the following we review algorithms for modeling intervention (treatment) effects. But before that let‚Äôs talk about another problem of ML which is <em>‚Äúcausation is not the same as correlation‚Äù</em>. Let‚Äôs demonstrate this in case of two very basic causal DAGs, Fork and Collider.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/dags.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Fork describes a process when a a single variable <strong>Z</strong> is affecting both <strong>X</strong> and <strong>Y</strong> and therefore they appear correlated even though there is is no causal link between them.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/fork.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The spurious correlation is gone only after conditioning both of them on <strong>Z</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/fork_conditioned.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In Collider <strong>X</strong> and <strong>Y</strong> are not causally linked but they both affect <strong>Z</strong>. One doesn‚Äôt observe any correlation between <strong>X</strong> and <strong>Y</strong>, as it should be.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/collider.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>But conditioning them on <strong>Z</strong> leads to a large $R^2$.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/collider_conditioned.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Therefore, ignoring causal links can also lead us to wrong decisions as they would be based on the spurious correlations.</p> <h2 id="definitions">Definitions</h2> <p>Estimating a treatment effect implies answering what if‚Ä¶ question or, in technical terms, estimating the corresponding counterfactual. Counterfactual refers to the value of the parameter of interest if intervention had not occur. So in the case of the churn use case, that would be the scenario when we never communicate with the customers. Another important concept is the treatment effect, which is the difference between the value of the parameter for the treated unit and the value the parameter for the treated unit would have had if we had not applied any treatment, Eq. 1.</p> <p>\begin{equation} TE = Y_T(t=1;W=1)-Y_T(t=1;W=0) \end{equation}</p> <p><strong>Y</strong> is the variable of interest where <strong>T</strong> stands for treatment group, <strong>t</strong> is a binary variable indicating whether it is measured in pre ($t=0$)- or post-intervention ($t=1$) period and <strong>W</strong> is also binary telling us whether treatment is applied or not. So by definition the second term in Eq.1 is counterfactual. Usually we want to calculate conditional average treatment effect given in Eq. 2.</p> <p>\begin{equation} CATE = E[Y_T(t=1;W=1)-Y_T(t=1;W=0)|X] \end{equation}</p> <p>Another term for the treatment effect coming from the marketing literature is uplift. It is used in the context of the interventions applied to a customer base.</p> <h2 id="algorithms-for-treatment-effect-estimation">Algorithms for Treatment Effect Estimation</h2> <h3 id="difference-in-differences-did">Difference in Differences (DiD)</h3> <p>So basically problem of treatment effect reduces to the counterfactual estimation because the first term in Eq. 2 is observed. There are two naive approximations for the counterfactual. The first one is to replace it with the value of $Y_T$ before the intervention.</p> \[CATE = E[Y_T(t=1;W=1)-Y_T(t=0;W=0)|X]\] <p>But this is not a good approximation because it assumes that there is no trend or seasonality in the time series and it changes only due the intervention. The second approximation is to utilize the control group in the post intervention period.</p> \[CATE = E[Y_T(t=1;W=1)-Y_C(t=1;W=0)|X]\] <p>But this approximation assumes that the control group is very similar to the treatment group in the pre-intervention period and would have remained similar if no treatment had been applied. That is also a strong assumption. Usually what‚Äôs used in practice is the combination of these two approximations resulting in the <strong>DiD</strong> estimator. So, counterfactual term is approximated with</p> \[\begin{align*} E[Y_T(t=1;W=0)|X]=&amp;E[Y_T(t=0;W=0)|X]+\\ &amp;+(E[Y_C(t=1;W=0)|X]-E[Y_C(t=0;W=0)|X]). \end{align*}\] <p>Plugging it into the equation of <strong>CATE</strong> yields</p> \[\begin{align*} CATE = &amp;(E[Y_T(t=1;W=1)|X] - E[Y_T(t=0;W=0)|X])-\\ &amp;-(E[Y_C(t=1;W=0)|X]-E[Y_C(t=0;W=0)|X]). \end{align*}\] <p>The first term is the difference between $Y_T$ values before and after intervention which is the treatment effect plus the change that would have occurred anyway. To cancel out the latter component the second term is subtracted which is a difference between $Y_C$ values before and after intervention. In other words we assume that the natural change that would have occurred in the treatment group is the same as in the control group. What if treatment and control time series have different scales? If this is the case let‚Äôs approximate the counterfactual using</p> \[\begin{align*} E[Y_T(t=1;W=0)|X]=E[Y_T(t=0;W=0)|X]\cdot \frac{E[Y_C(t=1;W=0)|X]}{E[Y_C(t=0;W=0)|X]} \end{align*}\] <p>resulting in</p> \[\begin{align*} CATE &amp;= (E[Y_T(t=1;W=1)|X] - E[Y_T(t=0;W=0)|X])-\\ &amp;-\frac{E[Y_T(t=0;W=0|X)]}{E[Y_C(t=0;W=0|X)]}\cdot(E[Y_C(t=1;W=0)|X]-E[Y_C(t=0;W=0)|X]) \end{align*}\] <p>more general expression in a sense that it reduces to the previous formula if the expectation of the treatment and control group values before the intervention are equal. Hence, to resolve issue of having different scales in the treatment and control time series ratio between pre- and post-intervention control group values is used instead of the absolute difference.</p> <h3 id="synthetic-control-brodersen-et-al-annals-of-applied-statistics-2015">Synthetic Control <d-footnote>Brodersen et al., Annals of Applied Statistics (2015)</d-footnote></h3> <p><strong>DiD</strong> requires treatment and control time series to have parallel trends and, in general, to be similar. This is quite strong requirement which is dropped by the synthetic control approach. Instead of finding a control time series very similar to the treated one let‚Äôs train a model on the bunch of untreated time series with output variable being the treated time series before the intervention. If the trained model has a good performance and accurately predicts the treated time series it can serve us as the control group. The model predictions in the post-intervention period represents counterfactual estimations. This is a very trivial but powerful idea. We don‚Äôt have to find time series similar to the treatment group, the only requirement is that the intervention does not affect them and they need to be predictive of the treatment time series.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/synthetic_control.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig 1. Synthetic control method </div> <p>Fig. 1 depicts this idea. $Y$ is the treated time series while $X_1$ and $X_2$ are input to the model that tries to predict $Y$. The dashed vertical line denotes the intervention. The solid blue is the fitted line whereas dashed blue line represents forecasts after the intervention. Therefore <strong>CATE</strong> would be the difference between solid black and dashed blue lines.</p> <h3 id="2-model-approach-s-athey-and-g-w-imbens-machine-learning-methods-for-estimating-heterogeneous-causal-effects-stat-10505-2015b">2-Model Approach <d-footnote>S. Athey and G. W. Imbens, Machine learning methods for estimating heterogeneous causal effects, stat, 1050:5, 2015b.</d-footnote></h3> <p>Another way of estimating <strong>CATE</strong> is to train two models on the treatment and the control group samples, respectively. Their predictions are estimates of the two terms in the definition of <strong>CATE</strong> in Eq. 2. This method can be reduced to the 1-model approach by combining treatment and control samples and adding <strong>W</strong>=(0,1) to the combined sample as one of the features.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/treatment_effect_estimation/2_model_approach.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig 2. Left: 2-model approach, Right: 1-model approach </div> <h3 id="target-transformation-approach">Target Transformation Approach</h3> <p>The disadvantage of the previous technique is that models have their own errors and after subtracting their predictions we are not guaranteed that those errors cancel each other. Most likely the treatment effect has even bigger error. To avoid it we introduce an approach which models <strong>CATE</strong> explicitly. Let‚Äôs first describe it in the case of the binary outcome followed by the general case.</p> <h4 id="binary-target-jaskowski-m--jaroszewicz-s-uplift-modeling-for-clinical-trial-data-icml-workshop-on-clinical-data-analysis-vol-46-2012">Binary Target <d-footnote>Jaskowski M., &amp; Jaroszewicz S., "Uplift modeling for clinical trial data." ICML Workshop on Clinical Data Analysis. Vol. 46. 2012</d-footnote></h4> <p><strong>CATE</strong> for the discrete target variable is defined in the following way</p> \[CATE = P(Y=1|X;W=1)-P(Y=1|X;W=0)\] <p>So it‚Äôs simply a probability of success in the treatment group minus the probability of success in the control group. Now introduce a new variable <strong>Z</strong></p> \[Z=Y\cdot W+(1-Y)\cdot (1-W).\] <p>Here is the list of all possible values of <strong>Z</strong>:</p> \[Z = \begin{cases} 1 &amp;\text{Y=1, $W=1 $}\\ 1 &amp;\text{Y=0, $W=0 $}\\ 0 &amp;\text{Y=0, $W=1 $}\\ 0 &amp;\text{Y=1, $W=0 $}\\ \end{cases}\] <p>Let‚Äôs compute the conditional probability of <strong>Z</strong> being 1.</p> \[P(Z=1|X)=P(Y=1|X;W=1)P(W=1|X)+P(Y=1|X;W=0)P(W=0|X)\] <p>Now we make an assumption of balanced treatment (whether an object is treated or not does not depend on $X$ and the probability of being treated is the same as the one of not being treated)</p> \[P(W=1|X)=P(W=0|X)=1/2\] <p>which simplifies the latter equation further and gives</p> \[P(Y=1|X;W=1)-P(Y=1|X;W=0)=2P(Z=1|X)-1\] <p>where left hand side is the definition of <strong>CATE</strong>. Therefore, modeling variable <strong>Z</strong> is the same as modeling uplift explicitly.</p> <h4 id="general-case-s-athey-and-g-w-imbens-machine-learning-methods-for-estimating-heterogeneous-causal-effects-stat-10505-2015b">General Case <d-footnote>S. Athey and G. W. Imbens, Machine learning methods for estimating heterogeneous causal effects, stat, 1050:5, 2015b.</d-footnote></h4> <p>In the previous section we made assumption of balanced treatment, meaning equal treatment and control groups, which, in general, doesn‚Äôt hold in practice. Also $W$ being independent of $X$ can‚Äôt be achieved unless we have completely randomized process. To drop that assumption consider another transformation of the outcome variable which does not have to be binary anymore.</p> \[Z=Y(W=1)\cdot \frac{W}{p(X)}-Y(W=0)\cdot \frac{1-W}{1-p(X)}\] <p>where</p> \[p(X)=P(W=1|X)\] <p>is a propensity score (this idea is similar to the inverse propensity weighting approach). Let‚Äôs compute the expectation value of <strong>Z</strong> as we did in the previous section.</p> \[E[Z|X]=\frac{E[Y(W=1)\cdot W|X]}{p(X)}-\frac{E[Y(W=0)\cdot (1-W)]}{1-p(X)}\] <p>Conditional Independence Assumption or Unconfoundedness (whether object is treated or not does not depend on the outcome)</p> \[W \perp (Y(W=1), Y(W=0))|X\] <p>reduces the equation to the definition of <strong>CATE</strong></p> \[E[Z|X]=E[Y(W=1)|X]-E[Y(W=0)|X].\] <p>Here we used the following relationship</p> \[E[W|X]=p(X).\] <p>Again, modeling <strong>Z</strong> gives the treatment effect directly.</p> <h2 id="summary">Summary</h2> <p>As we discussed in the introduction it is important to incorporate treatments in the modeling process otherwise we would make wrong decisions. This was the motivation for reviewing four different approaches for modeling the treatment effect. I think it is natural to group them into two different groups.</p> <table> <thead> <tr> <th>Uplift Estimation</th> <th>Uplift Prediction</th> </tr> </thead> <tbody> <tr> <td><strong>DiD</strong> Estimator</td> <td><strong>2-Model</strong> Approach</td> </tr> <tr> <td><strong>Synthetic Control</strong></td> <td><strong>Targete Transformation</strong> Method</td> </tr> </tbody> </table> <p><strong>DiD</strong> and <strong>Synthetic Control</strong> are used when intervention already occurred, post-intervention values of the treatment group are already observed and we want to estimate the effect. But if we want to predict the uplift before the intervention <strong>2-Model</strong> and <strong>Target Transformation</strong> approaches are relevant. And lastly, <strong>Synthetic Control</strong> is the only method out of these four which allows using time series of completely different variables than the one in the treatment group as a control and additionally, unlike <strong>DiD</strong>, it allows using the same variable but dissimilar time series compared to the treatment group as control.</p>]]></content><author><name>Andro Sabashvili</name></author><summary type="html"><![CDATA[Review of treatment effect estimation techniques]]></summary></entry><entry><title type="html">Cross-Validation Estimator</title><link href="https://androsaba.github.io/blog/2023/cross_validation_estimator/" rel="alternate" type="text/html" title="Cross-Validation Estimator"/><published>2023-10-23T00:00:00+00:00</published><updated>2023-10-23T00:00:00+00:00</updated><id>https://androsaba.github.io/blog/2023/cross_validation_estimator</id><content type="html" xml:base="https://androsaba.github.io/blog/2023/cross_validation_estimator/"><![CDATA[<h4 id="notations">Notations:</h4> <ul> <li>\(m\) - metric</li> <li>\(K\) - number of folds</li> <li>\(N\) - number of different training sample realizations (drawn from the true population)</li> <li>\(\overline{m^n}\) - average metric (over \(K\) folds) for a given training sample realization</li> <li>\(Var(m^n_k)\) - variance of a metric over \(K\) folds for a given training sample realization</li> <li>\(Var(\overline{m^n})\) - variance of an average metric (over different training sample realizations)</li> <li>\(Var(m)\) - True/population variance of a metric</li> </ul> <h2 id="bias">Bias</h2> <p>The goal of the cross-validation is to estimate the mean of a metric, \(\overline{m}\) and its variance, \(Var(m)\). Cross-validation gives a pessimistically biased estimate of a performance because most statistical models will improve if the training set is made larger. However, Leave-one-out cross-validation (LOOCV) is approximately unbiased, because the difference in size between the training set used in each fold and the entire dataset is only a single instance.</p> <h2 id="variance">Variance</h2> <p>Intra-fold variance of a metric \(Var(m^n_k)\) is affected by the sample size as well as how diverse the sample is or in other words how different are validation folds from each other. The folds can be quite different easily in the low data regime if there are some instabilities in the sample, like outliers (for instance, if a given validation fold is very different from the training fold the value of \(m^n_k\) can be very different from the other values and thus will increase its variance). To factor out the sample diversity/instabilities from the estimation of \(Var(m)\) cross-validation is repeated \(N\) times (\(N\) is a large number, say, 5000) with different training samples. As a result we get the \(N\) number of \(\overline{m^n}\) allowing us to compute the mean of means and the variance of means, \(Var(\overline{m^n})\) and that is what is usually referred to when discussing the variation of the CV estimator. If training samples are independent \(Var(\overline{m^n})\) is lower than that in the case of the correlated training samples based on the argument mentioned below.</p> <h2 id="effect-of-model-stability">Effect of Model Stability</h2> <p>Before we dive into the details one should mention that CV does a good job if we are dealing with large samples but small sample regime (e.g. 40-60 records) is a different story. Number of folds and instabilities have a prominent impact on the metric estimations in the latter scenario.</p> <p>Intuitively one thinks that with increasing \(K\) we get more overlapped training samples and thus almost the same models within CV, training folds become highly correlated. They make similar predictions (almost the same prediction if \(K\) is very large, for example, if \(K\) is the same as the number of data points which corresponds to LOOCV) for a given validation sample. Therefore these estimates of a metric are not independent, they are correlated and consequently lead to higher variance, \(Var(\overline{m^n})\) <a href="https://stats.stackexchange.com/questions/61783/bias-and-variance-in-leave-one-out-vs-k-fold-cross-validation/358138#358138">[ref]</a> (why the mean of a correlated data has larger variance than that of the independent one is explained <a href="https://stats.stackexchange.com/questions/223446/variance-of-the-mean-of-correlated-and-uncorrelated-data">here</a>).</p> <p>On the other hand one can show empirically that \(Var(\overline{m^n})\) doesn‚Äôt always increase with increasing \(K\) rather it depends on the stability of a model and a sample. If we are given a sample with no instabilities and a model is also stable<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> \(Var(\overline{m^n})\) goes down with increasing \(K\) (LOOCV gives minimum or almost minimum variance) (see Fig. 1) while for the unstable case it reaches minimum for some intermediate value of \(K\) (LOOCV is not minimum anymore) <a href="https://stats.stackexchange.com/questions/61783/bias-and-variance-in-leave-one-out-vs-k-fold-cross-validation/358138#358138">[ref]</a>. So the difference is in the high \(K\) region (see Fig. 2)<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/cross_validation_variance/CV_Variance_NoInstabilities_60points.png" class="img-fluid rounded medium-zoom-image large-image" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig1. Stable version: $Var(\overline{m^n})$ (left) and $Var(m^n_k)$ (right) as a function of $K$ </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/cross_validation_variance/CV_Variance_Instabilities_60points.png" class="img-fluid rounded medium-zoom-image large-image" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig2. Unstable version: $Var(\overline{m^n})$ (left) and $Var(m^n_k)$ (right) as a function of $K$ </div> <p>In general the variance is smaller in a stable environment compared to the unstable one. In the stable environment a given training sample is representative of the true distribution and thus \(\overline{m^n}\) is going to have similar values for different realizations of the training sample resulting in lower variance compared to the unstable scenario. In the latter case a given realization of the training sample is not representative of the underlying distribution. Imagine there are some instabilities in the sample, say, outliers. In the small data regime they may have a big influence on the model. For instance, if there are no outliers in the current realization of a sample (say, when \(n=1\)) we get stable model that behaves differently compared to the model we get, let‚Äôs say, in the next iteration (\(n=2\)) because in that realization outliers are present which is causing the fitted function to become more wavy/fluctuating. Due to that reason, outputs of these two models (\(n=1\) vs \(n=2\)) are going to be different and therefore there is larger difference between \(\overline{m^1}\) and \(\overline{m^2}\) leading to the higher variance, \(Var(\overline{m^n})\).</p> <p>In the low data regime \(Var(\overline{m^n})\) is large for smaller \(K\) values in both cases, stable and unstable environments. That is because when \(K\) is small the training fold becomes smaller and the model becomes very unstable as it is more sensitive to any noise/sampling artifacts in the particular training sample used <a href="https://stats.stackexchange.com/a/264721">[ref]</a>.</p> <table> <thead> <tr> <th>Model</th> <th>With Increasing K</th> </tr> </thead> <tbody> <tr> <td>Stable</td> <td>\(Var(m^n_k)\) increases, \(Var(\overline{m^n})\) decreases</td> </tr> <tr> <td>Unstable</td> <td>\(Var(m^n_k)\) increases, \(Var(\overline{m^n})\) has <strong>U</strong> shape (first goes down then goes up, like parabola)</td> </tr> </tbody> </table> <p>Now we try to explain why \(Var(\overline{m^n})\) goes (almost) monotonically down with respect to increasing \(K\) (even in high \(K\) region) for a stable model and why it goes up with increasing \(K\) (in high \(K\) region) in the case of an unstable model:</p> <h4 id="stable-model"><u>Stable Model</u></h4> <p>Intuitive explanation for decreasing variance \(Var(\overline{m^n})\) in case of the stable model is that going from \(K\) to \(K+1\) intra-fold variance \(Var(m^n_k)\) is increasing but the means (\(m^1\), \(m^2\),‚Ä¶, \(m^N\)) get closer to each other because the training samples gets bigger (more stable) so we get more similar estimates of a metric mean.</p> <h4 id="unstable-model"><u>Unstable Model</u></h4> <p>In case of the unstable model, initially variance is large because the training samples are very small and models are more unstable than for large \(K\) values. So increasing \(K\) makes models more stable, \(K\) is still small so intra-fold variance \(Var(m^n_k)\) is small and the means are closer to each other thus variance \(Var(\overline{m^n})\) goes down. At some point, for some intermediate value of \(K\) variance reaches its minimum and then it starts to go up. This happens because for larger \(K\) training samples become more correlated and given unstable environment (unstable model and/or sample with instabilities) intra-fold variances get very large and therefore the corresponding metric means get pushed further apart from each other. The models become more stable but it can‚Äôt cancel out the effect of increasing \(Var(m^n_k)\) leading to larger \(Var(\overline{m^n})\).</p> <h2 id="summary">Summary</h2> <p>For large samples the effect of stability is not significant. In a low data regime, whether a large number of folds is better or not depends on the stability of a model and a sample. In the case of a stable environment LOOCV is better than k-fold CV because of low variance and bias. In the case of instabilities some smaller number of folds seems to have lower variance than LOOCV. But one has to remember that the error of the estimator is a combination of bias and variance. So overall which one is better depends also on the bias term.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p><span class="footnote"> Variance of the cross validation estimator is a linear combination of three moments. The terms ùúî and ùõæ are influenced by correlation between the data sets, training sets, testing sets etc. and instability of the model. A model is stable if its output doesn‚Äôt change when deleting a point from the sample. These two effects are influenced by the value of ùêæ which explains why different datasets and models will lead to different behavior <a href="https://stats.stackexchange.com/questions/325123/why-does-k-fold-cross-validation-generate-an-mse-estimator-that-has-higher-bias/358504#358504">[ref]</a> </span>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2" role="doc-endnote"> <p><span class="footnote"> Getting the effect of increasing variance for large values of ùêæ is very senstive to the sample size and numeber of outliers. If a sample or number of outliers is larger their effect cancel out each other.</span>¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Andro Sabashvili</name></author><summary type="html"><![CDATA[Discussing the variance of the cross-validation estimator]]></summary></entry><entry><title type="html">Prediction Intervals for Aggregated Forecasts</title><link href="https://androsaba.github.io/blog/2023/prediction_interval_for_time_series/" rel="alternate" type="text/html" title="Prediction Intervals for Aggregated Forecasts"/><published>2023-10-09T00:00:00+00:00</published><updated>2023-10-09T00:00:00+00:00</updated><id>https://androsaba.github.io/blog/2023/prediction_interval_for_time_series</id><content type="html" xml:base="https://androsaba.github.io/blog/2023/prediction_interval_for_time_series/"><![CDATA[<h2 id="intro">Intro</h2> <p>I won‚Äôt go into details about why prediction intervals are important, we all know that. I just want to introduce a framework that will allow us to estimate a prediction interval for a single forecast, and then we will generalize it for aggregated forecasts. I started thinking about this problem when I was working on a sales forecasting model earlier this year. The model produced monthly forecasts, but the clients were interested in aggregated forecasts, such as annual sales of a store or forecasted annual sales for the entire shopping mall. I realized that I needed a way to estimate the prediction interval for aggregated forecasts, given that I only had a model that produced monthly forecasts.</p> <h2 id="distribution-free-approach">Distribution-free Approach</h2> <p>There are many approaches to building prediction intervals. Most of them are based on the residuals assumed that they are normally distributed. There are some fancy formulas that allow you to construct prediction intervals based on this normality assumption. However, we know that this assumption is often unrealistic and doesn‚Äôt hold in practice. I wanted to have a method that is distribution-free, so I decided to use a technique based on the bootstrapping approach. The basic idea is to simulate future paths of the variable of interest. This will allow us to estimate the distribution of the variable at any future time point. The technique can be used for supervised learning algorithms as well as time series algorithms.</p> <h2 id="simulating-future-paths">Simulating Future Paths</h2> <p>To generate a simulated path, we start with a forecast at the first time point in the horizon, \(T+1\), draw a random residual from the residual distribution and add it to the forecast. This gives us the first simulated value, \(y^*_{T+1}\). We then use the first simulated value as the input to the model to generate a forecast for the next time point in the horizon. We repeat this process until we have generated a sequence of simulated values for all of the future time points. This process is repeated multiple times to generate multiple simulated paths. This will give us a distribution of the variable of interesty at any future time point which is used to construct prediction intervals.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/Path_Equation.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="aggregation-across-different-dimensions">Aggregation Across Different Dimensions</h2> <p>We consider two types of aggregations:</p> <ul> <li>Aggregation across time axis is the process of combining forecasts for different time points into a single forecast. For example, if you have monthly forecasts for a year, you can aggregate them to get an annual forecast.</li> <li>Aggregation across time series is the process of combining forecasts for different time series into a single forecast. For example, if you have forecasts for sales of different products, you can aggregate them to get a forecast for total sales. Our method can be used to estimate prediction intervals for both, aggregation across time and aggregation across time series.</li> </ul> <h3 id="aggregation-across-time">Aggregation Across Time</h3> <p>For each simulated path, aggregate the monthly forecasts to obtain an annual forecast. This can be done by simply summing the monthly forecasts for each year (see equation below). As a result we are left with an array of \(N\) (number of simulated paths) elements for a given year, \((y_{1,year}, y_{2,year},..., y_{N,year})\). Estimate the lower and upper bounds of the prediction interval at the desired confidence level by computing \((1-\alpha)/2\)-th and \((1+\alpha)/2\)-th quantiles of the resulting distribution.</p> \[y^*_{s, 2027} = \sum^{12}_{m=1} y^*_{s,m/2027}\] <h3 id="aggregation-across-time-series">Aggregation Across Time Series</h3> <p>To estimate a prediction interval for an aggregated forecast across time series do a cross-section of the simulated paths for each time series at the time point of interest. Which gives us \(T\) (number of time series) arrays of length \(N\) (number of simulated paths in a single time series). Each array is a distribution of \(y\) at that time point. Therefore, we can say that we have a set of distributions of \(T\) random variables and the goal is to estimate the distribution of the sum of those random variables given that the distribution for each of them is known. One approach to do that is convolution but becomes infeasible when the number of random variables (time series) is large. More scalable and fast approach is Monte Carlo simulation: these arrays/distributions are put together in a matrix with columns being a distribution corresponding to a single time series. So, the matrix has an \(N \times T\) shape (\(N\) rows because there are \(N\) elements in a distribution since there are \(N\) paths, \(T\) columns - because we have \(T\) time series to aggregate). Then we sum the matrix entries horizontally resulting in the array of length \(N\) which is the estimation of the distribution of the aggregated forecasts. Estimate the lower and upper bounds of the prediction interval at the desired confidence level by computing quantiles of the resulting distribution.</p> \[\begin{bmatrix} y^{*,1}_{1} &amp; y^{*,2}_{1} &amp; y^{*,3}_{1} &amp; \cdots &amp; y^{*,T}_{1} \\ y^{*,1}_{2} &amp; y^{*,2}_{2} &amp; y^{*,3}_{2} &amp; \cdots &amp; y^{*,T}_{2} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ y^{*,1}_{N} &amp; y^{*,2}_{N} &amp; y^{*,3}_{N} &amp; \cdots &amp; y^{*,T}_{N} \\ \end{bmatrix} \begin{matrix} \\ \stackrel{\sum_t}{\Longrightarrow} \\ \\ \end{matrix} \begin{bmatrix} Y^*_{1} \\ Y^*_{2} \\ \vdots \\ Y^*_{N} \end{bmatrix}\] <h2 id="fit-prophet-into-the-framework">Fit Prophet into the Framework</h2> <p>Prophet has three main components: trend, seasonality and holidays. Trend is a major driver of the model. Prophet is a special algorithm in the sense that once a model is fitted, the trend has a constant slope and thus the Prophet model is blind, insensitive to the modifications we do to the input vector (adding a residual to the forecast). In order to generate the path one has to refit Prophet every time we update the input vector in order for the trend slope to be updated accordingly. But this approach is time consuming because the model needs to be fitted as many times as the number of time points in the forecasting horizon.</p> <p>To avoid that we make an approximation. We assume that the perturbation of the forecast affects only the trend component, others remain the same. We also need to remember how a trend is learned. First Prophet identifies change points in the original time series and the trend is simply a piecewise linear curve connecting all pairs of neighboring change points. So the slope of the trend is allowed to change only after it passes the change point otherwise it is constant.</p> <p>We utilize these ideas to generate a future path in the case of the Prophet model. First we need to come up with a way to check whether a simulated point is a change point or not. To do that we look at the change points Prophet identified from the original time series and calculate the smallest change in the trend components observed at those historical change points. After we simulate a future value, say, \(y^*_{T+1}\) , we check whether the previous point (in this case it would be \(y_T\), this is not a simulated point as it is the last value in the time series) is a change point. It is a change point if a change in trend component at that point is greater or equal to the observed smallest change at the historical change points. In such case trend is updated and becomes a line connecting \(y_T\) and \(y^*_{T+1}\) Otherwise the slope of the trend remains the same. This is how the trend is simulated for future values. In order to reconstruct original values \(y_t\) we add seasonality and holiday components to the simulated trend values (remember we assume that only trend is affected in the path simulation process and seasonality and holiday components are already estimated by Prophet for the entire horizon).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/Prophet_Trend.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="simulations">Simulations</h2> <p>Here we show some examples for prediction intervals constructed for the Prophet model. The first graph simply shows simulated paths for a time series. The second is with prediction intervals without any aggregation for the same time series. The next graph shows prediction intervals for annual aggregation. The fourth one shows prediction intervals for the forecasts that are the sum of the forecasts computed by different multiple models. And finally prediction intervals in the case of both types of aggregations: sum of the annual forecasts coming from different models.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/SimulatedPaths.png" class="img-fluid rounded medium-zoom-image large-image" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig1. Simulated paths </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/PredictionInterval_Positive.png" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig2. Prediction intervals before aggregation: solid blue line - actual values, dotted red - forecast, dotted green - 5-th percentile, dotted purple - 95-th percentile </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/PredictionInterval_TimeAggregated.png" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig3. Prediction intervals after annual aggregation: solid blue - aggregated forecast, dotted red - 5-th percentile, dotted green - 95-th percentile </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/PredictionInterval_TimeSeriesAggregated.png" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig4. Prediction intervals after aggregating multiple forecasts of different models: solid blue line - actual values, dotted red - forecast, dotted green - 5-th percentile, dotted purple - 95-th percentile </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prediction_intervals/PredictionInterval_Time_TimeSeries_Aggregated.png" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig5. Prediction intervals after aggregating annual forecasts of different models: solid blue - aggregated forecast, dotted red - 5-th percentile, dotted green - 95-th percentile </div> <h2 id="summary">Summary</h2> <p>The benefit of simulated path based approach for calculating prediction intervals is that it is distribution-free, generalizable for aggregated forecasts, easy to implement and it is fast. What it lacks is drift adaptation mechanism. We also made an approximation but that is Prophet specific. No need to make similar approximation if another algorithm is used for time series modeling.</p>]]></content><author><name>Andro Sabashvili</name></author><summary type="html"><![CDATA[A framework for constructing prediction intervals]]></summary></entry></feed>